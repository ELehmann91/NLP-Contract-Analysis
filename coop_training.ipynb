{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coop_training",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ELehmann91/NLP-Contract-Analysis/blob/master/coop_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKvZ1y3d3Ak8",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lG3ReZc9ESyVPsstjuu5ek73u6vVsi3X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzJ2Uy6TTt58",
        "colab_type": "text"
      },
      "source": [
        "# Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BhrT_sQMiH0",
        "colab_type": "text"
      },
      "source": [
        "Setting up the environment in Colab to run various experiments, note the cuda version of spacy-pytorch-transformers is being downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTBAcallXvFv",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/explosion/spacy-transformers/issues/39"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9SFfHSVfK0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#!python -m spacy download en_trf_bertbaseuncased_lg\n",
        "#!python -m spacy download de_trf_bertbasecased_lg\n",
        "!pip install spacy==2.2.0\n",
        "!pip install torch==1.1.0\n",
        "#!pip install spacy-transformers\n",
        "#!python -m spacy download de_trf_bertbasecased_lg\n",
        "!pip install PyPDF2\n",
        "!sudo apt install poppler-utils\n",
        "!pip install pdf2image\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install spacy\n",
        "!pip install spacy-langdetect\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHnQiSqRZFLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install gputil\n",
        "#!pip install torch==1.1.0\n",
        "#!pip install spacy-pytorch-transformers[cuda100]==0.2.0\n",
        "#!pip install spacy==2.2.0\n",
        "#!python -m spacy download de_pytt_bertbasecased_lg #spacy 2.1.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j0oHvNgMwms",
        "colab_type": "text"
      },
      "source": [
        "You will need to **restart runtime after these installs** to reinstatiate the environment/directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt50zr1JOe5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "import numpy\n",
        "from numpy.testing import assert_almost_equal\n",
        "from scipy.spatial import distance\n",
        "from spacy.util import minibatch\n",
        "import random\n",
        "#import cupy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import joblib\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvEvWmLf41LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mawRzX0q4rb6",
        "colab_type": "text"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8afe5gEP3NMb",
        "colab_type": "code",
        "outputId": "088a2e87-34c4-4c56-93da-da002b2597cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IfnMbAL3NaQ",
        "colab_type": "code",
        "outputId": "e116b46a-e83e-40fb-e1ee-0876dce786b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = '/content/gdrive/Shared drives/FS-AI Base Data/innolytiq_pdf/'\n",
        "file_list = os.listdir(path)\n",
        "len(file_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kimChQfzofmy",
        "colab_type": "text"
      },
      "source": [
        "## OCR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgq7-j7ipLVx",
        "colab_type": "text"
      },
      "source": [
        "writes text file for pdfs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqlu-7lDoYFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def OCR_pdf(path_,file_,no_pages=10):\n",
        "    filename = path_ + file_ +'/' + file_ +'.pdf' #'target.pdf'\n",
        "    if os.path.exists(path_+ file_+'/extracted_text.txt') == False:\n",
        "\n",
        "        # import pdf to img\n",
        "        with tempfile.TemporaryDirectory() as path:\n",
        "            # mag page number\n",
        "            images_from_path = convert_from_path(filename, output_folder=path, last_page=no_pages, first_page =0)\n",
        "        #filename\n",
        "        base_filename  =  os.path.splitext(os.path.basename(filename))[0] + '.jpg'     \n",
        "        #create folder for images\n",
        "        img_dir = path_ + file_ + '/pdf2img'\n",
        "        try:\n",
        "          os.mkdir(img_dir)\n",
        "        except FileExistsError:\n",
        "          next\n",
        "          #print('check')\n",
        "\n",
        "        text = ''\n",
        "        for i,page in enumerate(images_from_path):\n",
        "            #save as jpg\n",
        "            page.save(os.path.join(img_dir, base_filename+str(i)), 'JPEG')\n",
        "            #read jpg and extract text\n",
        "            text += pytesseract.image_to_string(Image.open(os.path.join(img_dir, base_filename+str(i)))) + ' '\n",
        "            #\n",
        "        file1 = open(path_+ file_+'/extracted_text.txt','w') \n",
        "        file1.writelines(text) \n",
        "        file1.close()\n",
        "\n",
        "        #print(filename,'pages:',len(images_from_path))\n",
        "    else:\n",
        "      next\n",
        "      #print(filename,' allready exists')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W3VNzy9oYX_",
        "colab_type": "code",
        "outputId": "139b2dc0-e469-4ebe-cb8e-2c13ad817f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "path_ = '/content/gdrive/Shared drives/FS-AI Base Data/innolytiq_pdf/'\n",
        "file_list = os.listdir(path_)\n",
        "\n",
        "for file_ in tqdm(file_list):\n",
        "    OCR_pdf(path_,file_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/149 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 149/149 [00:00<00:00, 6711.17it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTaCLRVr4xVE",
        "colab_type": "text"
      },
      "source": [
        "## Build Dataframe from data.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHMkFaa_qw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name list contains lists of columns\n",
        "name_list = []\n",
        "\n",
        "with open(path + file_list[0]+'/data.json', encoding=\"utf8\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for line in data['output']:\n",
        "        try: #line['members'] is not None:\n",
        "            name_list.append(line['name'])\n",
        "        except:\n",
        "            print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVQuzWkmToux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create empty dataframe\n",
        "df_ = pd.DataFrame(index=file_list, columns=name_list)\n",
        "df_ = df_.fillna(0) # with 0s rather than NaNs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqOxUgUjTo8K",
        "colab_type": "code",
        "outputId": "2d56b5a3-a3f7-4351-ceb2-7693fbc296ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# read data from json to dataframe\n",
        "for file in tqdm(file_list):\n",
        "    with open(path+file+'/data.json', encoding=\"utf8\") as json_file:\n",
        "        data = json.load(json_file)\n",
        "        #print(data)\n",
        "        try:\n",
        "            for line in data['output']:\n",
        "                try: # line['members'] is not None:\n",
        "                    df_.loc[df_.index==file,line['name']] = line['data'][0]['value']\n",
        "                except:\n",
        "                    pass\n",
        "                    #print(line['name'])\n",
        "        except KeyError:\n",
        "            print(file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/149 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 6/149 [00:00<00:02, 53.64it/s]\u001b[A\n",
            "  8%|▊         | 12/149 [00:00<00:02, 54.89it/s]\u001b[A\n",
            " 13%|█▎        | 19/149 [00:00<00:02, 56.58it/s]\u001b[A\n",
            " 17%|█▋        | 26/149 [00:00<00:02, 57.79it/s]\u001b[A\n",
            " 22%|██▏       | 33/149 [00:00<00:01, 59.05it/s]\u001b[A\n",
            " 27%|██▋       | 40/149 [00:00<00:01, 60.22it/s]\u001b[A\n",
            " 32%|███▏      | 47/149 [00:00<00:01, 60.81it/s]\u001b[A\n",
            " 36%|███▌      | 53/149 [00:00<00:01, 59.73it/s]\u001b[A\n",
            " 40%|████      | 60/149 [00:01<00:01, 60.05it/s]\u001b[A\n",
            " 44%|████▍     | 66/149 [00:01<00:01, 59.26it/s]\u001b[A\n",
            " 48%|████▊     | 72/149 [00:01<00:01, 56.80it/s]\u001b[A\n",
            " 52%|█████▏    | 78/149 [00:01<00:01, 56.51it/s]\u001b[A\n",
            " 56%|█████▋    | 84/149 [00:01<00:01, 57.20it/s]\u001b[A\n",
            " 60%|██████    | 90/149 [00:01<00:01, 57.80it/s]\u001b[A\n",
            " 64%|██████▍   | 96/149 [00:01<00:00, 58.34it/s]\u001b[A\n",
            " 68%|██████▊   | 102/149 [00:01<00:00, 58.79it/s]\u001b[A\n",
            " 73%|███████▎  | 109/149 [00:01<00:00, 58.89it/s]\u001b[A\n",
            " 78%|███████▊  | 116/149 [00:01<00:00, 59.61it/s]\u001b[A\n",
            " 82%|████████▏ | 122/149 [00:02<00:00, 59.42it/s]\u001b[A\n",
            " 86%|████████▌ | 128/149 [00:02<00:00, 59.22it/s]\u001b[A\n",
            " 90%|████████▉ | 134/149 [00:02<00:00, 57.79it/s]\u001b[A\n",
            " 94%|█████████▍| 140/149 [00:02<00:00, 58.25it/s]\u001b[A\n",
            " 98%|█████████▊| 146/149 [00:02<00:00, 58.04it/s]\u001b[A\n",
            "100%|██████████| 149/149 [00:02<00:00, 58.74it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49VaEIGr47X2",
        "colab_type": "text"
      },
      "source": [
        "## Read PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgWpI3mAGcSt",
        "colab_type": "code",
        "outputId": "936f6e56-8197-44d5-f64e-776d1154a3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_['pdf_text'] = 'leer'\n",
        "i=1\n",
        "for file_ in tqdm(file_list):\n",
        "    #print(i)\n",
        "    try:\n",
        "      with open(path+file_+'/extracted_text.txt',\"r\") as file1:\n",
        "        text = file1.readlines()\n",
        "        text = ''.join([t.replace('\\n',' ') for t in text])\n",
        "        file1.close() \n",
        "        \n",
        "        #print('name:',file_,'words:',len(text.split()))\n",
        "        df_['pdf_text'][df_.index==file_] = text\n",
        "        i+=1\n",
        "    except:\n",
        "        df_['pdf_text'][df_.index==file_] = 'leer'\n",
        "        print('cant read '+file_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/149 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/149 [00:00<00:46,  3.20it/s]\u001b[A\n",
            "  1%|▏         | 2/149 [00:00<00:48,  3.03it/s]\u001b[A\n",
            "  2%|▏         | 3/149 [00:00<00:47,  3.08it/s]\u001b[A\n",
            "  3%|▎         | 4/149 [00:01<00:48,  3.02it/s]\u001b[A\n",
            "  3%|▎         | 5/149 [00:01<00:48,  2.96it/s]\u001b[A\n",
            "  4%|▍         | 6/149 [00:01<00:45,  3.13it/s]\u001b[A\n",
            "  5%|▍         | 7/149 [00:02<00:44,  3.21it/s]\u001b[A\n",
            "  5%|▌         | 8/149 [00:02<00:44,  3.20it/s]\u001b[A\n",
            "  6%|▌         | 9/149 [00:02<00:42,  3.30it/s]\u001b[A\n",
            "  7%|▋         | 10/149 [00:03<00:43,  3.18it/s]\u001b[A\n",
            "  7%|▋         | 11/149 [00:03<00:42,  3.23it/s]\u001b[A\n",
            "  8%|▊         | 12/149 [00:03<00:42,  3.25it/s]\u001b[A\n",
            "  9%|▊         | 13/149 [00:04<00:41,  3.31it/s]\u001b[A\n",
            "  9%|▉         | 14/149 [00:04<00:40,  3.37it/s]\u001b[A\n",
            " 10%|█         | 15/149 [00:04<00:39,  3.41it/s]\u001b[A\n",
            " 11%|█         | 16/149 [00:05<00:41,  3.21it/s]\u001b[A\n",
            " 11%|█▏        | 17/149 [00:05<00:40,  3.25it/s]\u001b[A\n",
            " 12%|█▏        | 18/149 [00:05<00:41,  3.12it/s]\u001b[A\n",
            " 13%|█▎        | 19/149 [00:05<00:40,  3.25it/s]\u001b[A\n",
            " 13%|█▎        | 20/149 [00:06<00:39,  3.30it/s]\u001b[A\n",
            " 14%|█▍        | 21/149 [00:06<00:39,  3.25it/s]\u001b[A\n",
            " 15%|█▍        | 22/149 [00:06<00:39,  3.24it/s]\u001b[A\n",
            " 15%|█▌        | 23/149 [00:07<00:39,  3.17it/s]\u001b[A\n",
            " 16%|█▌        | 24/149 [00:07<00:39,  3.15it/s]\u001b[A\n",
            " 17%|█▋        | 25/149 [00:07<00:38,  3.22it/s]\u001b[A\n",
            " 17%|█▋        | 26/149 [00:08<00:39,  3.11it/s]\u001b[A\n",
            " 18%|█▊        | 27/149 [00:08<00:38,  3.17it/s]\u001b[A\n",
            " 19%|█▉        | 28/149 [00:08<00:38,  3.11it/s]\u001b[A\n",
            " 19%|█▉        | 29/149 [00:09<00:41,  2.90it/s]\u001b[A\n",
            " 20%|██        | 30/149 [00:09<00:39,  3.00it/s]\u001b[A\n",
            " 21%|██        | 31/149 [00:09<00:38,  3.04it/s]\u001b[A\n",
            " 21%|██▏       | 32/149 [00:10<00:37,  3.11it/s]\u001b[A\n",
            " 22%|██▏       | 33/149 [00:10<00:38,  3.05it/s]\u001b[A\n",
            " 23%|██▎       | 34/149 [00:10<00:37,  3.07it/s]\u001b[A\n",
            " 23%|██▎       | 35/149 [00:11<00:37,  3.03it/s]\u001b[A\n",
            " 24%|██▍       | 36/149 [00:11<00:36,  3.13it/s]\u001b[A\n",
            " 25%|██▍       | 37/149 [00:11<00:34,  3.21it/s]\u001b[A\n",
            " 26%|██▌       | 38/149 [00:12<00:37,  2.99it/s]\u001b[A\n",
            " 26%|██▌       | 39/149 [00:12<00:35,  3.06it/s]\u001b[A\n",
            " 27%|██▋       | 40/149 [00:12<00:34,  3.17it/s]\u001b[A\n",
            " 28%|██▊       | 41/149 [00:13<00:38,  2.82it/s]\u001b[A\n",
            " 28%|██▊       | 42/149 [00:13<00:36,  2.92it/s]\u001b[A\n",
            " 29%|██▉       | 43/149 [00:13<00:34,  3.03it/s]\u001b[A\n",
            " 30%|██▉       | 44/149 [00:14<00:34,  3.07it/s]\u001b[A\n",
            " 30%|███       | 45/149 [00:14<00:33,  3.11it/s]\u001b[A\n",
            " 31%|███       | 46/149 [00:14<00:32,  3.19it/s]\u001b[A\n",
            " 32%|███▏      | 47/149 [00:15<00:33,  3.07it/s]\u001b[A\n",
            " 32%|███▏      | 48/149 [00:15<00:32,  3.11it/s]\u001b[A\n",
            " 33%|███▎      | 49/149 [00:15<00:32,  3.10it/s]\u001b[A\n",
            " 34%|███▎      | 50/149 [00:15<00:31,  3.18it/s]\u001b[A\n",
            " 34%|███▍      | 51/149 [00:16<00:30,  3.19it/s]\u001b[A\n",
            " 35%|███▍      | 52/149 [00:16<00:31,  3.05it/s]\u001b[A\n",
            " 36%|███▌      | 53/149 [00:16<00:31,  3.08it/s]\u001b[A\n",
            " 36%|███▌      | 54/149 [00:17<00:30,  3.12it/s]\u001b[A\n",
            " 37%|███▋      | 55/149 [00:17<00:29,  3.14it/s]\u001b[A\n",
            " 38%|███▊      | 56/149 [00:17<00:29,  3.18it/s]\u001b[A\n",
            " 38%|███▊      | 57/149 [00:18<00:28,  3.20it/s]\u001b[A\n",
            " 39%|███▉      | 58/149 [00:18<00:30,  3.01it/s]\u001b[A\n",
            " 40%|███▉      | 59/149 [00:18<00:29,  3.08it/s]\u001b[A\n",
            " 40%|████      | 60/149 [00:19<00:29,  2.98it/s]\u001b[A\n",
            " 41%|████      | 61/149 [00:19<00:28,  3.06it/s]\u001b[A\n",
            " 42%|████▏     | 62/149 [00:19<00:28,  3.01it/s]\u001b[A\n",
            " 42%|████▏     | 63/149 [00:20<00:28,  3.05it/s]\u001b[A\n",
            " 43%|████▎     | 64/149 [00:20<00:27,  3.05it/s]\u001b[A\n",
            " 44%|████▎     | 65/149 [00:20<00:27,  3.08it/s]\u001b[A\n",
            " 44%|████▍     | 66/149 [00:21<00:26,  3.11it/s]\u001b[A\n",
            " 45%|████▍     | 67/149 [00:21<00:26,  3.08it/s]\u001b[A\n",
            " 46%|████▌     | 68/149 [00:21<00:27,  2.96it/s]\u001b[A\n",
            " 46%|████▋     | 69/149 [00:22<00:25,  3.10it/s]\u001b[A\n",
            " 47%|████▋     | 70/149 [00:22<00:24,  3.26it/s]\u001b[A\n",
            " 48%|████▊     | 71/149 [00:22<00:25,  3.10it/s]\u001b[A\n",
            " 48%|████▊     | 72/149 [00:23<00:23,  3.26it/s]\u001b[A\n",
            " 49%|████▉     | 73/149 [00:23<00:23,  3.29it/s]\u001b[A\n",
            " 50%|████▉     | 74/149 [00:23<00:22,  3.39it/s]\u001b[A\n",
            " 50%|█████     | 75/149 [00:23<00:21,  3.46it/s]\u001b[A\n",
            " 51%|█████     | 76/149 [00:24<00:21,  3.33it/s]\u001b[A\n",
            " 52%|█████▏    | 77/149 [00:24<00:21,  3.31it/s]\u001b[A\n",
            " 52%|█████▏    | 78/149 [00:24<00:22,  3.18it/s]\u001b[A\n",
            " 53%|█████▎    | 79/149 [00:25<00:22,  3.12it/s]\u001b[A\n",
            " 54%|█████▎    | 80/149 [00:25<00:21,  3.22it/s]\u001b[A\n",
            " 54%|█████▍    | 81/149 [00:25<00:22,  3.07it/s]\u001b[A\n",
            " 55%|█████▌    | 82/149 [00:26<00:21,  3.17it/s]\u001b[A\n",
            " 56%|█████▌    | 83/149 [00:26<00:23,  2.76it/s]\u001b[A\n",
            " 56%|█████▋    | 84/149 [00:26<00:23,  2.80it/s]\u001b[A\n",
            " 57%|█████▋    | 85/149 [00:27<00:22,  2.91it/s]\u001b[A\n",
            " 58%|█████▊    | 86/149 [00:27<00:21,  2.98it/s]\u001b[A\n",
            " 58%|█████▊    | 87/149 [00:27<00:20,  3.00it/s]\u001b[A\n",
            " 59%|█████▉    | 88/149 [00:28<00:19,  3.13it/s]\u001b[A\n",
            " 60%|█████▉    | 89/149 [00:28<00:19,  3.04it/s]\u001b[A\n",
            " 60%|██████    | 90/149 [00:28<00:19,  3.10it/s]\u001b[A\n",
            " 61%|██████    | 91/149 [00:29<00:18,  3.06it/s]\u001b[A\n",
            " 62%|██████▏   | 92/149 [00:29<00:22,  2.49it/s]\u001b[A\n",
            " 62%|██████▏   | 93/149 [00:30<00:20,  2.69it/s]\u001b[A\n",
            " 63%|██████▎   | 94/149 [00:30<00:20,  2.67it/s]\u001b[A\n",
            " 64%|██████▍   | 95/149 [00:30<00:19,  2.75it/s]\u001b[A\n",
            " 64%|██████▍   | 96/149 [00:31<00:18,  2.88it/s]\u001b[A\n",
            " 65%|██████▌   | 97/149 [00:31<00:17,  3.03it/s]\u001b[A\n",
            " 66%|██████▌   | 98/149 [00:31<00:16,  3.14it/s]\u001b[A\n",
            " 66%|██████▋   | 99/149 [00:32<00:16,  3.09it/s]\u001b[A\n",
            " 67%|██████▋   | 100/149 [00:32<00:15,  3.19it/s]\u001b[A\n",
            " 68%|██████▊   | 101/149 [00:32<00:14,  3.21it/s]\u001b[A\n",
            " 68%|██████▊   | 102/149 [00:33<00:16,  2.85it/s]\u001b[A\n",
            " 69%|██████▉   | 103/149 [00:33<00:15,  2.90it/s]\u001b[A\n",
            " 70%|██████▉   | 104/149 [00:33<00:15,  2.99it/s]\u001b[A\n",
            " 70%|███████   | 105/149 [00:34<00:14,  3.00it/s]\u001b[A\n",
            " 71%|███████   | 106/149 [00:34<00:14,  2.93it/s]\u001b[A\n",
            " 72%|███████▏  | 107/149 [00:34<00:14,  2.91it/s]\u001b[A\n",
            " 72%|███████▏  | 108/149 [00:35<00:14,  2.87it/s]\u001b[A\n",
            " 73%|███████▎  | 109/149 [00:35<00:13,  3.03it/s]\u001b[A\n",
            " 74%|███████▍  | 110/149 [00:35<00:12,  3.16it/s]\u001b[A\n",
            " 74%|███████▍  | 111/149 [00:35<00:11,  3.19it/s]\u001b[A\n",
            " 75%|███████▌  | 112/149 [00:36<00:12,  2.87it/s]\u001b[A\n",
            " 76%|███████▌  | 113/149 [00:36<00:12,  2.87it/s]\u001b[A\n",
            " 77%|███████▋  | 114/149 [00:37<00:11,  2.93it/s]\u001b[A\n",
            " 77%|███████▋  | 115/149 [00:37<00:11,  2.94it/s]\u001b[A\n",
            " 78%|███████▊  | 116/149 [00:37<00:10,  3.04it/s]\u001b[A\n",
            " 79%|███████▊  | 117/149 [00:38<00:11,  2.75it/s]\u001b[A\n",
            " 79%|███████▉  | 118/149 [00:38<00:12,  2.49it/s]\u001b[A\n",
            " 80%|███████▉  | 119/149 [00:38<00:11,  2.72it/s]\u001b[A\n",
            " 81%|████████  | 120/149 [00:39<00:10,  2.77it/s]\u001b[A\n",
            " 81%|████████  | 121/149 [00:39<00:10,  2.74it/s]\u001b[A\n",
            " 82%|████████▏ | 122/149 [00:39<00:09,  2.86it/s]\u001b[A\n",
            " 83%|████████▎ | 123/149 [00:40<00:08,  3.00it/s]\u001b[A\n",
            " 83%|████████▎ | 124/149 [00:40<00:08,  3.12it/s]\u001b[A\n",
            " 84%|████████▍ | 125/149 [00:40<00:07,  3.23it/s]\u001b[A\n",
            " 85%|████████▍ | 126/149 [00:41<00:07,  3.22it/s]\u001b[A\n",
            " 85%|████████▌ | 127/149 [00:41<00:06,  3.22it/s]\u001b[A\n",
            " 86%|████████▌ | 128/149 [00:41<00:06,  3.24it/s]\u001b[A\n",
            " 87%|████████▋ | 129/149 [00:42<00:06,  3.29it/s]\u001b[A\n",
            " 87%|████████▋ | 130/149 [00:42<00:05,  3.28it/s]\u001b[A\n",
            " 88%|████████▊ | 131/149 [00:42<00:05,  3.31it/s]\u001b[A\n",
            " 89%|████████▊ | 132/149 [00:43<00:05,  3.18it/s]\u001b[A\n",
            " 89%|████████▉ | 133/149 [00:43<00:04,  3.21it/s]\u001b[A\n",
            " 90%|████████▉ | 134/149 [00:43<00:04,  3.05it/s]\u001b[A\n",
            " 91%|█████████ | 135/149 [00:43<00:04,  3.15it/s]\u001b[A\n",
            " 91%|█████████▏| 136/149 [00:44<00:04,  3.23it/s]\u001b[A\n",
            " 92%|█████████▏| 137/149 [00:44<00:03,  3.19it/s]\u001b[A\n",
            " 93%|█████████▎| 138/149 [00:44<00:03,  3.16it/s]\u001b[A\n",
            " 93%|█████████▎| 139/149 [00:45<00:03,  2.67it/s]\u001b[A\n",
            " 94%|█████████▍| 140/149 [00:45<00:03,  2.74it/s]\u001b[A\n",
            " 95%|█████████▍| 141/149 [00:46<00:02,  2.89it/s]\u001b[A\n",
            " 95%|█████████▌| 142/149 [00:46<00:02,  2.98it/s]\u001b[A\n",
            " 96%|█████████▌| 143/149 [00:46<00:01,  3.08it/s]\u001b[A\n",
            " 97%|█████████▋| 144/149 [00:47<00:01,  3.05it/s]\u001b[A\n",
            " 97%|█████████▋| 145/149 [00:47<00:01,  3.11it/s]\u001b[A\n",
            " 98%|█████████▊| 146/149 [00:47<00:01,  2.89it/s]\u001b[A\n",
            " 99%|█████████▊| 147/149 [00:48<00:00,  2.99it/s]\u001b[A\n",
            " 99%|█████████▉| 148/149 [00:48<00:00,  2.83it/s]\u001b[A\n",
            "100%|██████████| 149/149 [00:48<00:00,  2.69it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx8-AACh3PGD",
        "colab_type": "code",
        "outputId": "1485ca1f-8fa7-4a02-853c-913aa39b1b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "print(df_.shape)\n",
        "df_[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>006_issue_date</th>\n",
              "      <th>009_nominal_amount</th>\n",
              "      <th>008_maturity_date</th>\n",
              "      <th>010_redemption_formula</th>\n",
              "      <th>011_seniority</th>\n",
              "      <th>012_business_day_convention</th>\n",
              "      <th>014_business_day_calendar</th>\n",
              "      <th>017_first_payment_date</th>\n",
              "      <th>018_payment_dates</th>\n",
              "      <th>021_formula</th>\n",
              "      <th>002_issuer_name</th>\n",
              "      <th>020_paragraph_489</th>\n",
              "      <th>004_identifiers</th>\n",
              "      <th>007_issue_price</th>\n",
              "      <th>003_product_subclass</th>\n",
              "      <th>015_payment_frequency</th>\n",
              "      <th>005_currency</th>\n",
              "      <th>013_day_count_convention</th>\n",
              "      <th>001_type</th>\n",
              "      <th>004_wkn</th>\n",
              "      <th>004_isin</th>\n",
              "      <th>023_amendment</th>\n",
              "      <th>022_legislation</th>\n",
              "      <th>pdf_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>erfurter_bank_eg.pdf</th>\n",
              "      <td>22.02.2013</td>\n",
              "      <td>5.000.000,00</td>\n",
              "      <td>22.02.2022</td>\n",
              "      <td>Nennwert</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>22.02.2014</td>\n",
              "      <td>22.02.</td>\n",
              "      <td>2,34 Prozent</td>\n",
              "      <td>Die Erfurter Bank eG</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>100,00%</td>\n",
              "      <td>Schuldschein</td>\n",
              "      <td>1</td>\n",
              "      <td>EUR</td>\n",
              "      <td>act/act</td>\n",
              "      <td>Fixed</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>no_amendment</td>\n",
              "      <td>Ger</td>\n",
              "      <td>NU IV UAAYY G  SCHULDSCHEIN  Die Erfurter Bank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de000dr0q3k7_en.pdf</th>\n",
              "      <td>23 July 2008</td>\n",
              "      <td>100,000,000</td>\n",
              "      <td>21 September 2012</td>\n",
              "      <td>100%</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>21 September 2009</td>\n",
              "      <td>21 September 2009 \\n21 September 2010 \\n21 Sep...</td>\n",
              "      <td>10 years EURO - Swap minus 2 years EURO Swap a...</td>\n",
              "      <td>Dresdner Bank Aktiengesellschaft, Frankfurt am...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>other Loan</td>\n",
              "      <td>1</td>\n",
              "      <td>EUR</td>\n",
              "      <td></td>\n",
              "      <td>Floating</td>\n",
              "      <td>DR0Q3K</td>\n",
              "      <td>DE 000 DR0 Q3K 7</td>\n",
              "      <td>no_amendment</td>\n",
              "      <td>Ger</td>\n",
              "      <td>Dresdner Bank AG Private Investor Products  +4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     006_issue_date  ...                                           pdf_text\n",
              "erfurter_bank_eg.pdf     22.02.2013  ...  NU IV UAAYY G  SCHULDSCHEIN  Die Erfurter Bank...\n",
              "de000dr0q3k7_en.pdf    23 July 2008  ...  Dresdner Bank AG Private Investor Products  +4...\n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LlChMVm5POC",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJLj7Oz13dl1",
        "colab_type": "code",
        "outputId": "0186b43c-cd03-4b9b-8058-8bd8c02e5d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "sw_en = stopwords.words('english')\n",
        "sw_de = stopwords.words('german')\n",
        "sw_en.extend(sw_de)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XAtqpby5Pjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def propro(sen):\n",
        "  sen = sen.lower()\n",
        "  sen = sen.replace('\\n',' ')\n",
        "  sen = sen.replace('%','prozent')\n",
        "  sen = re.sub('[^A-Za-zÄÖÜßäöüß]+', ' ',sen)\n",
        "  sen = ' '.join([w for w in sen.split() if w not in sw_en])\n",
        "  return sen\n",
        "\n",
        "df_['pdf_text_prepro'] = df_['pdf_text'].apply(lambda x: propro(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_nGOt_ZfA6t",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-tIzHDkQ1VF",
        "colab_type": "text"
      },
      "source": [
        "## Classification - LogReg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtLRkTZukK8k",
        "colab_type": "text"
      },
      "source": [
        "### 003_product_subclass'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nzVz3X7kbYE",
        "colab_type": "code",
        "outputId": "c458470d-b73e-4aba-9658-aae3d68feca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df_['003_product_subclass'] = df_['003_product_subclass'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['003_product_subclass'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bond                                             68\n",
              "Schuldschein                                     26\n",
              "other Loan                                       19\n",
              "Covered Bond                                     18\n",
              "no_class                                          6\n",
              "SCHULDVERSCHREIBUNGSTYP                           3\n",
              "Term Loan                                         2\n",
              "(the \"Securities\") \\nSchuldverschreibungen\"       2\n",
              "TYPE OF SECURITIES  \\nSCHULDVERSCHREIBUNGSTYP     2\n",
              "chuldverschreibungen\"                             1\n",
              "\"Schuldverschreibungen\"                           1\n",
              "Anleihe                                           1\n",
              "Name: 003_product_subclass, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M68Nuc0cxbOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bool_col = (np.where(df_['003_product_subclass']=='Bond',True,False) +\n",
        "            np.where(df_['003_product_subclass']=='Schuldschein',True,False) +\n",
        "            np.where(df_['003_product_subclass']=='other Loan',True,False) +\n",
        "            np.where(df_['003_product_subclass']=='Covered Bond',True,False) +\n",
        "            np.where(df_['003_product_subclass']=='no_class',True,False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POoupMEuxuM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojwCqJxJOZiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'][bool_col], \n",
        "                                                    df_['003_product_subclass'][bool_col],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1_g_mn3E72Q",
        "colab_type": "code",
        "outputId": "51ac78cb-4196-4e2c-b8aa-f7d35e43f50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression( C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.8571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITqlVId330zM",
        "colab_type": "code",
        "outputId": "42e9bbef-f1dc-4f60-af23-896670ad3078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction: Bond /// true_val: Bond\n",
            "prediction: Bond /// true_val: Bond\n",
            "prediction: Schuldschein /// true_val: Schuldschein\n",
            "prediction: Bond /// true_val: Bond\n",
            "prediction: Bond /// true_val: Bond\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZyGNbcLqdm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '003_product_subclass_model.joblib'\n",
        "#joblib.dump(logreg, save_path+filename)\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " \n",
        "\n",
        "# load the model from disk\n",
        "#loaded_model = pickle.load(open(filename, 'rb'))\n",
        "#result = loaded_model.score(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDzHTGfFeAmN",
        "colab_type": "code",
        "outputId": "92f81a03-7acf-4881-b4b3-89557350de22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_path+filename"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/Shared drives/FS-AI Base Data/models/003_product_subclass_model.joblib'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg0YnMFarDZn",
        "colab_type": "code",
        "outputId": "e71a3de4-4aa9-40e1-f777-511cbe4af9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#loaded_model = pickle.load(open(save_path+filename, 'rb'))\n",
        "loaded_model = joblib.load(save_path+filename)\n",
        "pred = loaded_model.predict(df_['pdf_text_prepro'])\n",
        "result = loaded_model.score(df_['pdf_text_prepro'], df_['003_product_subclass'])\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8926174496644296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij2UD1iFexC7",
        "colab_type": "code",
        "outputId": "21d2bd33-7a7f-48d7-935f-493984c159db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "pred = loaded_model.predict(df_['pdf_text_prepro'][1])\n",
        "pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-546eeb752bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pdf_text_prepro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m                 \"string object received.\")\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWyMPWb4kPgi",
        "colab_type": "text"
      },
      "source": [
        "### 011_seniority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__WqcP6BkP_Q",
        "colab_type": "code",
        "outputId": "9f567f12-ce20-4408-d696-d11446d7c730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df_['011_seniority'] = df_['011_seniority'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['011_seniority'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_class            79\n",
              "Senior Secured      29\n",
              "Senior              29\n",
              "Senior Unsecured     9\n",
              "Unsecured            2\n",
              "Subordinated         1\n",
              "Name: 011_seniority, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Om94NEkQHE",
        "colab_type": "code",
        "outputId": "5efdeb3e-294b-4ee9-aeee-a43c6b4b50f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['011_seniority'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '011_seniority_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.6333333333333333\n",
            "prediction:  /// true_val: \n",
            "prediction:  /// true_val: \n",
            "prediction: Senior Secured /// true_val: Senior\n",
            "prediction:  /// true_val: \n",
            "prediction: Senior /// true_val: Senior\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mTf801NkWnG",
        "colab_type": "text"
      },
      "source": [
        "### 012_business_day_convention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KQhrbckW18",
        "colab_type": "code",
        "outputId": "f4195ae3-d150-4304-d378-81b0ee0bec64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df_['012_business_day_convention'] = df_['012_business_day_convention'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['012_business_day_convention'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_class                         70\n",
              "Following unadjusted             41\n",
              "Unadjusted                       17\n",
              "Modified following adjusted       7\n",
              "Following adjusted                6\n",
              "Modified following unadjusted     4\n",
              "Adjusted                          3\n",
              "Modified Following                1\n",
              "Name: 012_business_day_convention, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwO2zdrUkQMV",
        "colab_type": "code",
        "outputId": "e86a1099-50d2-404e-c376-d1b21cbdd7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['012_business_day_convention'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '012_business_day_convention_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.6666666666666666\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: Following adjusted /// true_val: Following adjusted\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: Following unadjusted /// true_val: Unadjusted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWVyHZD8kmc7",
        "colab_type": "text"
      },
      "source": [
        "### 022_legislation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDhJlpnlTnx",
        "colab_type": "code",
        "outputId": "87842fd5-053b-48a2-f2a6-b6d2f71a107a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "df_['022_legislation'] = df_['022_legislation'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['022_legislation'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_class                    82\n",
              "Ger                         41\n",
              "German Law                   8\n",
              "Netherlands                  7\n",
              "NLD                          5\n",
              "London,                      3\n",
              "Stockholm, London            1\n",
              "ederlandse \\nNetherlands     1\n",
              "German law.                  1\n",
              "Name: 022_legislation, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7RfWM925LRw",
        "colab_type": "code",
        "outputId": "c3cddc0d-0b45-4c7f-9065-98fb26e75f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['022_legislation'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '022_legislation_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.5\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: Ger /// true_val: Ger\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: German Law\n",
            "prediction: no_class /// true_val: Netherlands\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ANfCf1koea",
        "colab_type": "text"
      },
      "source": [
        "### 020_paragraph_489"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBTah8QvlUg7",
        "colab_type": "code",
        "outputId": "ff5c85d5-75d3-437c-d56f-72de75de703a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_['020_paragraph_489'] = df_['020_paragraph_489'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['020_paragraph_489'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_class                      115\n",
              "Excluded                       25\n",
              "Not Excluded                    8\n",
              "10 Jahren gemäß § 489 Abs.      1\n",
              "Name: 020_paragraph_489, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOR8MgBq8noA",
        "colab_type": "code",
        "outputId": "1ef8e7c0-dee6-4aaa-de6c-618e46928d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['020_paragraph_489'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '020_paragraph_489_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.8\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpyqtIvIkoo7",
        "colab_type": "text"
      },
      "source": [
        "### 023_amendment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6XHxcqAlVbU",
        "colab_type": "code",
        "outputId": "d1a9ad17-3b3f-404e-f730-c39d3bbe878b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_['023_amendment'] = df_['023_amendment'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['023_amendment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no_amendment    79\n",
              "no_class        69\n",
              "amendment        1\n",
              "Name: 023_amendment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlMrfpt39Cca",
        "colab_type": "code",
        "outputId": "ce1b5ebd-3bfa-45ec-e07c-e4d7d2ab81d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['023_amendment'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '023_amendment_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.7666666666666667\n",
            "prediction: no_amendment /// true_val: no_amendment\n",
            "prediction: no_amendment /// true_val: no_amendment\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_amendment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPRI7kCNk6LB",
        "colab_type": "text"
      },
      "source": [
        "### 005_currency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiuLY8wtlXSF",
        "colab_type": "code",
        "outputId": "53e9e8be-9af7-4768-ab01-a79b0bc5db61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "df_['005_currency'] = df_['005_currency'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['005_currency'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EUR             80\n",
              "Euro            26\n",
              "USD             11\n",
              "Euro (€)         7\n",
              "no_class         7\n",
              "(\"EUR\")          4\n",
              "Euro (\"EUR\")     2\n",
              "UR\"              1\n",
              "('NZD\")          1\n",
              "Euro (\"EUR')     1\n",
              "CHF              1\n",
              "GBP              1\n",
              "Euro (EtlR)      1\n",
              "SEK              1\n",
              "(\"EUR\" o         1\n",
              "AUD              1\n",
              "GBP (\"GBP\")      1\n",
              "other            1\n",
              "(ELIR)           1\n",
              "Name: 005_currency, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehIlFHnW9Feb",
        "colab_type": "code",
        "outputId": "11efcd9f-51bb-4abc-c26d-862df7bab6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['005_currency'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '005_currency_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.5666666666666667\n",
            "prediction: EUR /// true_val: EUR\n",
            "prediction: EUR /// true_val: EUR\n",
            "prediction: USD /// true_val: USD\n",
            "prediction: Euro /// true_val: Euro (\"EUR\")\n",
            "prediction: Euro (EtlR) /// true_val: EUR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kIgOZkak6IM",
        "colab_type": "text"
      },
      "source": [
        "### 015_payment_frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa1wILGKlYCc",
        "colab_type": "code",
        "outputId": "e5c166f9-3eaf-4933-eb85-d250e00199f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_['015_payment_frequency'] = df_['015_payment_frequency'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['015_payment_frequency'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1           109\n",
              "4            14\n",
              "0            14\n",
              "no_class      7\n",
              "2             5\n",
              "Name: 015_payment_frequency, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNkLUe19HAD",
        "colab_type": "code",
        "outputId": "d2905c96-7b88-4031-ad25-84f50dc28cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['015_payment_frequency'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '015_payment_frequency_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.9333333333333333\n",
            "prediction: 1 /// true_val: 1\n",
            "prediction: no_class /// true_val: 1\n",
            "prediction: 4 /// true_val: 4\n",
            "prediction: 1 /// true_val: 2\n",
            "prediction: 1 /// true_val: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfzX2OmJlGcE",
        "colab_type": "text"
      },
      "source": [
        "### 014_business_day_calendar\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy4lYihelY2J",
        "colab_type": "code",
        "outputId": "35396027-96f3-4778-cb26-41530476ef4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df_['014_business_day_calendar'] = df_['014_business_day_calendar'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['014_business_day_calendar'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TARGET2                         81\n",
              "no_class                        37\n",
              "TARGET                          21\n",
              "'l'ARGE'l'a                      1\n",
              "Euromarket\\nTARGET2              1\n",
              "Clearing Sy\\n(TARGET2)           1\n",
              ", TARGET 2                       1\n",
              "TARGET2,                         1\n",
              "London and TARGET2               1\n",
              "TARGET a                         1\n",
              "TARGET & Sydney                  1\n",
              "London and TARGET                1\n",
              "New York, London and TARGET2     1\n",
              "Name: 014_business_day_calendar, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yznJ0PoA9IC-",
        "colab_type": "code",
        "outputId": "b51cf8d2-6cc3-42d1-d8d2-02a83db3b8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['014_business_day_calendar'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '014_business_day_calendar_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9915966386554622\n",
            "accuracy 0.7666666666666667\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: TARGET2 /// true_val: TARGET2\n",
            "prediction: TARGET2 /// true_val: TARGET2\n",
            "prediction: TARGET2 /// true_val: TARGET2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8wox25TlGmI",
        "colab_type": "text"
      },
      "source": [
        "### 013_day_count_convention\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqAexQVolZps",
        "colab_type": "code",
        "outputId": "09b65281-a5b2-47d4-b75b-b9b37abd5c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "df_['013_day_count_convention'] = df_['013_day_count_convention'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['013_day_count_convention'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Act/act ICMA               44\n",
              "no_class                   32\n",
              "Actual/Actual (ICMA)       20\n",
              "30/360                     15\n",
              "Act/360                     9\n",
              "act/act                     7\n",
              "301360                      5\n",
              "ActuaVActual (ICMA)         3\n",
              "Actual / Actual (ICMA)      3\n",
              "30E/360                     2\n",
              "Actual/360                  2\n",
              "\"Accrual Period             1\n",
              "ActuaV360                   1\n",
              "Actual/Actual               1\n",
              "Act/365 L, Act/act ICMA     1\n",
              "Act/act ISDA                1\n",
              "Actual/365                  1\n",
              "ActuaU360                   1\n",
              "Name: 013_day_count_convention, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgyoDl949JU4",
        "colab_type": "code",
        "outputId": "dc64886f-5b37-43d0-ff58-c3de96f697e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['013_day_count_convention'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '013_day_count_convention_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1.0\n",
            "accuracy 0.4666666666666667\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: no_class /// true_val: no_class\n",
            "prediction: Act/360 /// true_val: Actual/360\n",
            "prediction: Actual/Actual (ICMA) /// true_val: Actual/360\n",
            "prediction: 301360 /// true_val: Actual/Actual (ICMA)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QdyhuSDlHN6",
        "colab_type": "text"
      },
      "source": [
        "###\t001_type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvP4f9BmlafL",
        "colab_type": "code",
        "outputId": "9ba4f3ec-f1c6-4708-8a65-03da3fa8fa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_['001_type'] = df_['001_type'].apply(lambda x: 'no_class' if x == '' else x)\n",
        "df_['001_type'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fixed         96\n",
              "Floating      44\n",
              "no_class       4\n",
              "Zero           3\n",
              "Fixed Rate     2\n",
              "Name: 001_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YQbyWXE9Lif",
        "colab_type": "code",
        "outputId": "9804c373-167d-456f-e056-42602f295ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_['pdf_text_prepro'], \n",
        "                                                    df_['001_type'],\n",
        "                                                    random_state=42,\n",
        "                                                    #stratify=y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(C=1e7)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_train)\n",
        "y_pred_ = logreg.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_train))\n",
        "print('accuracy %s' % accuracy_score(y_pred_, y_test))\n",
        "\n",
        "for i in range(0,5):\n",
        "  print('prediction:',y_pred_[i],'/// true_val:',y_test[i])\n",
        "\n",
        "# save the model to disk\n",
        "save_path = '/content/gdrive/Shared drives/FS-AI Base Data/models/'\n",
        "filename = '001_type_model.sav'\n",
        "pickle.dump(logreg, open(save_path+filename, 'wb'))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9915966386554622\n",
            "accuracy 0.8333333333333334\n",
            "prediction: Fixed /// true_val: Fixed\n",
            "prediction: Floating /// true_val: Floating\n",
            "prediction: Floating /// true_val: Floating\n",
            "prediction: Fixed /// true_val: Floating\n",
            "prediction: Fixed /// true_val: Fixed Rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJDwoFwxRI3f",
        "colab_type": "text"
      },
      "source": [
        "## Extraction - Manul Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp4TJI0HRl6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_de = spacy.load(\"de_core_news_sm\")\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy_langdetect import LanguageDetector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J4w2ef3RHqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_corpus(text):\n",
        "  '''\n",
        "  check if german or english and use spacy language model accordingly \n",
        "  return spacy doc\n",
        "  '''\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "  doc = nlp(text)\n",
        "  # document level language detection. Think of it like average language of the document!\n",
        "  if doc._.language['language'] == 'en':\n",
        "    #print('english detected')\n",
        "    doc = nlp_en(text)\n",
        "  elif doc._.language['language'] == 'de':\n",
        "    #print('german detected')\n",
        "    doc = nlp_en(text)\n",
        "  else:\n",
        "    print('not found', doc._.language['language'])\n",
        "  return doc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-rowE5EmuxX",
        "colab_type": "text"
      },
      "source": [
        "### 007_issue_price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n97k3Qim1M1",
        "colab_type": "code",
        "outputId": "8e1e7839-2dcb-4159-cb74-fe69f90f8d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "df_['007_issue_price'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100                                                                                                                                                                                                           37\n",
              "100.00                                                                                                                                                                                                        27\n",
              "                                                                                                                                                                                                              26\n",
              "100,00                                                                                                                                                                                                         3\n",
              "100                                                                                                                                                                                                            3\n",
              "101,50%                                                                                                                                                                                                        2\n",
              "100.00                                                                                                                                                                                                         2\n",
              "100 per cent                                                                                                                                                                                                   2\n",
              "100.934                                                                                                                                                                                                        1\n",
              "20.70%                                                                                                                                                                                                         1\n",
              "101.35075                                                                                                                                                                                                      1\n",
              "99.942                                                                                                                                                                                                         1\n",
              "100,081%                                                                                                                                                                                                       1\n",
              "101.063                                                                                                                                                                                                        1\n",
              "91.080                                                                                                                                                                                                         1\n",
              "100%                                                                                                                                                                                                           1\n",
              "55.43123858                                                                                                                                                                                                    1\n",
              "102.7308 per cent                                                                                                                                                                                              1\n",
              "99.717                                                                                                                                                                                                         1\n",
              "99.757                                                                                                                                                                                                         1\n",
              "98.49                                                                                                                                                                                                          1\n",
              "100.00 per cent. of the Aggregate Nominal Amount\\nplus 78 days' accrued interest rate amounting to USD\\n237,358.33 from, and including the Interest\\nCommencement Date to, but excluding, the Issue\\nDate.     1\n",
              "100 %                                                                                                                                                                                                          1\n",
              "103.160                                                                                                                                                                                                        1\n",
              "100.1180%                                                                                                                                                                                                      1\n",
              "98.578                                                                                                                                                                                                         1\n",
              "100 per cent.                                                                                                                                                                                                  1\n",
              "99.484                                                                                                                                                                                                         1\n",
              "99.838                                                                                                                                                                                                         1\n",
              "100.044%                                                                                                                                                                                                       1\n",
              "108.317                                                                                                                                                                                                        1\n",
              "99.962                                                                                                                                                                                                         1\n",
              "100.0750/o                                                                                                                                                                                                     1\n",
              "98.829                                                                                                                                                                                                         1\n",
              "99.964                                                                                                                                                                                                         1\n",
              "84,789                                                                                                                                                                                                         1\n",
              "100,00%                                                                                                                                                                                                        1\n",
              "100.57                                                                                                                                                                                                         1\n",
              "99.941 per cent. of the Aggregate Nominal Amount\\nplus 37 days' accrued interest rate amounting to USD\\n225,186.11 from, and including the Interest\\nCommencement Date to, but excluding, the Issue\\nDate.     1\n",
              "88.304                                                                                                                                                                                                         1\n",
              "85.842                                                                                                                                                                                                         1\n",
              "99.04909%                                                                                                                                                                                                      1\n",
              "100.081                                                                                                                                                                                                        1\n",
              "99.284                                                                                                                                                                                                         1\n",
              "98.268                                                                                                                                                                                                         1\n",
              "98.94                                                                                                                                                                                                          1\n",
              "85.769                                                                                                                                                                                                         1\n",
              "100.058                                                                                                                                                                                                        1\n",
              "109.216                                                                                                                                                                                                        1\n",
              "99.765                                                                                                                                                                                                         1\n",
              "89.422                                                                                                                                                                                                         1\n",
              "88.871                                                                                                                                                                                                         1\n",
              "88.570                                                                                                                                                                                                         1\n",
              "100.744                                                                                                                                                                                                        1\n",
              "100.775                                                                                                                                                                                                        1\n",
              "Name: 007_issue_price, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65HfWrN7RICr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_ident(doc,ident_list,window_w=150):\n",
        "  '''\n",
        "  input spacy doc and list with string identifiers\n",
        "  loops throgh the document and searches for identifiers\n",
        "  if found return a window of words\n",
        "  '''\n",
        "  windows = []\n",
        "  for i, token in enumerate(doc):\n",
        "      if token.text in ident_list:\n",
        "        window = [tok for tok in doc[i-1:i+window_w]]\n",
        "        windows.extend(window)\n",
        "      if doc[i-1].text +' '+ token.text in ident_list:\n",
        "        window = [tok for tok in doc[i-2:i+window_w]]\n",
        "        windows.extend(window)\n",
        "      #print(token.text, token.pos_, token.tag_, token.dep_, token.shape_)\n",
        "  return windows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRqCmCY_RIIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_number(doc,length=8,min=60,max=200):\n",
        "  '''\n",
        "  scans through a documents for numers between 60 and 200\n",
        "  '''\n",
        "  for tok in doc:\n",
        "    tag = tok.tag_ in ['CD','CARD']\n",
        "    lgt = len(tok.text)<length\n",
        "    try:\n",
        "      num_o = min < float(re.sub('[^0-9.,]', ' ',tok.text).replace(',','.')) < max\n",
        "    except:\n",
        "      bum_o = False\n",
        "      next\n",
        "    if tag and lgt and num_o:\n",
        "      return tok.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYyKpUmVU1h",
        "colab_type": "code",
        "outputId": "f7edae6b-b067-46de-ffd4-2649415c5046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test = 'Der Ausgabepreis 100,000,0.00 beträgt 101,50 Euro und fünfzig'\n",
        "doc = nlp_de(test)\n",
        "find_number(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'101,50'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdr7vionSBOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#identifier\n",
        "issue_price_ident = [\"Ausgabepreis\", \"Issue Price\", \"Emissionskurs\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-oUZ8gxRIOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "issue_no = []\n",
        "for i in range(0,len(df_)):\n",
        "  text = df_['pdf_text'][i]\n",
        "  doc = multi_corpus(text)\n",
        "  window = find_ident(doc,issue_price_ident)\n",
        "  no = find_number(window)\n",
        "  #print(i,df_.index[i],window,no,df_['007_issue_price'][i])\n",
        "  issue_no.append(no)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcE2lX50jPbq",
        "colab_type": "code",
        "outputId": "da449ccf-9bf3-4903-efdc-e49de0b8660f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=0\n",
        "for i in range(0,len(issue_no)):\n",
        "\n",
        "  if issue_no[i]==df_['007_issue_price'][i]:\n",
        "    a +=1\n",
        "\n",
        "a/len(issue_no)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5167785234899329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tqvQpWEnpgB",
        "colab_type": "text"
      },
      "source": [
        "### 004_wkn\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsUNFkh6nsy8",
        "colab_type": "code",
        "outputId": "1d19632f-04a5-427f-865c-0202663c042a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_['004_wkn'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           87\n",
              "DR0Q3K      3\n",
              "DR0 Q16     2\n",
              "DR4WDY      2\n",
              "DR9RHD      2\n",
              "DR0 QUQ     2\n",
              "DL19TJ      1\n",
              "DR5 DQ4     1\n",
              "DR6YTN      1\n",
              "DL19T4      1\n",
              "DL19S3      1\n",
              "DL19TG      1\n",
              "DL19T5      1\n",
              "DL19S4      1\n",
              "A1ZW6A      1\n",
              "HSH3J4      1\n",
              "DB5DCC      1\n",
              "DL19ST      1\n",
              "DL19T9      1\n",
              "DR5XZF      1\n",
              "DR0Q3D      1\n",
              "A2E4ZD      1\n",
              "A1AZR0      1\n",
              "DL19T0      1\n",
              "CB83GN      1\n",
              "A0FAG7      1\n",
              "DL19T7      1\n",
              "DR1 VLH     1\n",
              "DL19SZ      1\n",
              "DR0 RVP     1\n",
              "DR0Q0E      1\n",
              "DR0PUN      1\n",
              "DL19UH      1\n",
              "DL19SK      1\n",
              "DL19UY      1\n",
              "DL19UL      1\n",
              "DL19T8      1\n",
              "DR0FL3      1\n",
              "DL19TK      1\n",
              "DL19UK      1\n",
              "DL19TF      1\n",
              "CZ3 1P5     1\n",
              "DL19S9      1\n",
              "DE04XK      1\n",
              "DL19TL      1\n",
              "A0E83L      1\n",
              "DL19TE      1\n",
              "CB8 3HP     1\n",
              "DB5DBZ      1\n",
              "A1H3V5      1\n",
              "A2BPC4      1\n",
              "DR6 D0M     1\n",
              "DL19UU      1\n",
              "CZ2 25Q     1\n",
              "DR1 WF5     1\n",
              "DL19TH      1\n",
              "757 271     1\n",
              "Name: 004_wkn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2edaiYMnpnw",
        "colab_type": "text"
      },
      "source": [
        "### 004_isin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y3cqCbLntVf",
        "colab_type": "code",
        "outputId": "926f5fd7-793f-4a8e-d37a-30a6a9ed17e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['004_isin'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      15\n",
              "X51992160827           3\n",
              "DE 000 DR0 Q16 9       2\n",
              "DE 000 DR0 Q3K 7       2\n",
              "DE 000 DR0 QUQ 5       2\n",
              "                      ..\n",
              "DE000A0FAG76           1\n",
              "DE000DR0PUN4           1\n",
              ":DEOCOAOES3I5          1\n",
              "DE000A2E4ZD1           1\n",
              "I\\nXS 142037 955 I     1\n",
              "Name: 004_isin, Length: 126, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbqsg2tqm9Ti",
        "colab_type": "text"
      },
      "source": [
        "### 006_issue_date\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9PdddgDm99v",
        "colab_type": "code",
        "outputId": "f9710348-8b4a-466c-afee-1d9c9e7942be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['006_issue_date'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    18\n",
              "13 November 2018     2\n",
              "24 March 2017        2\n",
              "27 July 2018         2\n",
              "23 July 2008         2\n",
              "                    ..\n",
              "August 6, 2007       1\n",
              "29th may 2007        1\n",
              "18 April 2019        1\n",
              "30. Juni 2011        1\n",
              "March 22, 2010       1\n",
              "Name: 006_issue_date, Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1RI3nkhnNF5",
        "colab_type": "text"
      },
      "source": [
        "### 009_nominal_amount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZddfevtdnvnA",
        "colab_type": "code",
        "outputId": "dc4ea204-6edf-4d33-81c9-2a13e4a3eb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['009_nominal_amount'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10,000,000       14\n",
              "20,000,000        6\n",
              "100,000,000       6\n",
              "5.000.000,00      5\n",
              "40,000,000        4\n",
              "                 ..\n",
              "25,000,000        1\n",
              "50,500,000        1\n",
              "6,000,000,000     1\n",
              "800.000.000,-     1\n",
              "1,730,000,000     1\n",
              "Name: 009_nominal_amount, Length: 96, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC9yWYgcnNN6",
        "colab_type": "text"
      },
      "source": [
        "###\t008_maturity_date\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzsCyWiMnwcQ",
        "colab_type": "code",
        "outputId": "e6a2dab9-edc1-4383-b412-8880b22319b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['008_maturity_date'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4 October 2041        7\n",
              "27 May 2036           5\n",
              "24February 2020       3\n",
              "9 August 2019         3\n",
              "14 January 2021       2\n",
              "                     ..\n",
              "24 October 2039       1\n",
              "7. August 2012        1\n",
              "11. Juli 2011         1\n",
              "29 January 2020       1\n",
              "21. September 2012    1\n",
              "Name: 008_maturity_date, Length: 129, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdk_gH0BnP21",
        "colab_type": "text"
      },
      "source": [
        "### 010_redemption_formula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-p_NFSNnxXx",
        "colab_type": "code",
        "outputId": "ce80b7ed-bbf3-4662-9704-a603f1f9a836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "df_['010_redemption_formula'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          104\n",
              "100%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       15\n",
              "Nennwert                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    4\n",
              "100 per cent                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                3\n",
              "100 per cent.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3\n",
              "Nennbetrag                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2\n",
              "100                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2\n",
              "100,00%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2\n",
              "The investor receives at the Redemption Date a cash amount according fo the\\nfollowing formula:\\n4\\nD*:| 100%+P matx oono[{USDUSIpCoo ow DsICC—yeYY,Ui,aSDgICoCn)|Y,\\nWhere:\\nD = Denomination\\nP = Participation\\nW,= Theweightof eachbasketcomponentB. asketis equallyweighted\\nUSDICcy,,,, =ThefixingofBaskectomponeinatgainstht eUSDattime\\n17:05ontheFinalFixingDateon BloombergWMCO\\nUSD/Ccy =ThefixingofBaskectompone|natgainstht eUSDonthe\\ninitial fixingdajtey, accordingto tableabove                                                                                                                                                                                                                                                                            1\n",
              "On Maturity Date, the Notewill redeem at 100% plus any Conditional Coupon at\\nMaturity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
              "zu pari                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
              "Gesamtnennbetrag                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
              "Nominalwert                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
              "Redemption at par                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
              "A) Wird der Basiswert am letzten Feststellungstag gleich oder oberhalb des Strikes \\nfestgestellt, erfolgt die Rückzahlung zu 100% des Nominalbetrages plus Prämie \\nB) Wird der Basiswert am letzten Feststellungstag unterhalb des Strikes festgestellt, erfolgt \\ndie Rückzahlung zu 100% des Nominalbetrages \\nFalls der Referenzwert zum jeweiligen Feststellungstag gleich oder oberhalb des Strikes \\nfestgestellt wird, \\n1) 7% des Nominals im ersten Laufzeitjahr \\n2) 13% des Nominals im zweiten Laufzeitjahr \\n3) 20% des Nominals im dritten Laufzeitjahr \\n4,95% \\nSollte an einem Feststellungstag der Basiswert gleich oder größer dem Strike festgestellt \\nwerden, erfolgt die Rückzahlung des Zertifikates zu 100% des Nominalbetrages plus Prämie      1\n",
              "at par                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
              "Zinsintervall: 28.11.9z].                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
              "zum Nennwert                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
              "On Maturity Date, the Notewill redeem at 100%plus any Coupon at Maturity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
              "Redemption/Payment Basis: 138.977 euro per cent or 1 389.77 per Bond                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
              "A) If the underlying will be fixed at or above the strike on last observation date the investor \\nreceives 100% of nominal plus premium repayment \\nB) If the underlying will be fixed below the strike on last observation date the investor \\nreceives 100% of nominal repayment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
              "100,00% des Nennbetrages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
              "Name: 010_redemption_formula, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfbwk9e8nNTo",
        "colab_type": "text"
      },
      "source": [
        "### 017_first_payment_dat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kb2ajT8nyHF",
        "colab_type": "code",
        "outputId": "bcd63fbe-d02a-4128-e040-a5333a920350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['017_first_payment_date'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     35\n",
              "27 May 2019           4\n",
              "10 November 2019      4\n",
              "27 May 2018           3\n",
              "4 October 2019        2\n",
              "                     ..\n",
              " 24 December 20l9     1\n",
              "28. August 2016       1\n",
              "10 August 2019        1\n",
              "18 January 2020       1\n",
              "8 September 2017      1\n",
              "Name: 017_first_payment_date, Length: 100, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P98UgWdQndPF",
        "colab_type": "text"
      },
      "source": [
        "### 018_payment_dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6aTcPzKnzBM",
        "colab_type": "code",
        "outputId": "1f0f8bc5-dcb4-4966-c705-ce4057b68ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_['018_payment_dates'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               13\n",
              "4 October       8\n",
              "27 May          5\n",
              "29 January      3\n",
              "10 February     3\n",
              "               ..\n",
              "08.07.          1\n",
              "20. Juli        1\n",
              "14 June         1\n",
              "25.05.          1\n",
              "22 May          1\n",
              "Name: 018_payment_dates, Length: 111, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dh86HU_Op-_",
        "colab_type": "text"
      },
      "source": [
        "Checks whether GPU is available, switches to cuda if it is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MfBlpUiKVKt",
        "colab_type": "code",
        "outputId": "ee0baa84-4559-469d-faa2-b71688af6e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "is_using_gpu = spacy.prefer_gpu()\n",
        "if is_using_gpu:\n",
        "    print(\"Using GPU!\")\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "    print(\"GPU Usage\")\n",
        "    GPUtil.showUtilization()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU!\n",
            "GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  0% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObcNBdbUq4j",
        "colab_type": "text"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3rrcd320tdz5",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install ktrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b3985b70-c415-4f71-f561-8ff57465c032",
        "id": "oR8lNrVdtYj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "using Keras version: 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5loLZgtxXF2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bert = df_[['pdf_text','003_product_subclass']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zep8qrHKgmQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use pd.concat to join the new columns with your original dataframe\n",
        "df_bert = pd.concat([df_bert,pd.get_dummies(df_bert['003_product_subclass'])],axis=1)\n",
        "\n",
        "# now drop the original 'country' column (you don't need it anymore)\n",
        "df_bert.drop(['003_product_subclass'],axis=1, inplace=True)\n",
        "df_bert = df_bert[['pdf_text','Bond','Schuldschein']]#,'other Loan','Covered Bond']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl9AFaAMboh3",
        "colab_type": "code",
        "outputId": "79849b8d-27f0-41fc-a1ca-022f09d7a2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_bert['is1'] = df_bert['Bond'] + df_bert['Schuldschein']\n",
        "df_bert = df_bert[df_bert['is1']==1]\n",
        "df_bert.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvRjFY4oK5wV",
        "colab_type": "code",
        "outputId": "810febe4-d369-45e4-8d4c-dc4f28af068c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(df_bert, \n",
        "                                                                   'pdf_text', # name of column containing review text\n",
        "                                                                   label_columns=['Bond','Schuldschein'],\n",
        "                                                                   maxlen=500, \n",
        "                                                                   lang='ze',\n",
        "                                                                   preprocess_mode='bert',\n",
        "                                                                   val_pct=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: ze\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: ze\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwbQ7p3K5qM",
        "colab_type": "code",
        "outputId": "a30883c0-248d-4908-8f11-8d5fd042464a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "model = text.text_classifier('bert', (x_train, y_train) , preproc=preproc)\n",
        "learner = ktrain.get_learner(model, \n",
        "                             train_data=(x_train, y_train), \n",
        "                             val_data=(x_test, y_test), \n",
        "                             batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chhydCBSjTxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using 1cycle learning rate schedule for 3 epochs\n",
        "learner.fit_onecycle(2e-5, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}